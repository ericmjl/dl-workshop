{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap, grad\n",
    "import jax.numpy as np\n",
    "from jax.scipy import stats\n",
    "from jax import random\n",
    "from jax.scipy.special import logsumexp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mixture gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "weights_true = np.array([1, 5])\n",
    "means_true = np.array([-2, 3])\n",
    "\n",
    "base_n_draws = 1000\n",
    "key = random.PRNGKey(100)\n",
    "\n",
    "draws_1 = random.normal(key, shape=(base_n_draws * weights_true[0],)) + means_true[0]\n",
    "draws_2 = random.normal(key, shape=(base_n_draws * weights_true[1],)) + means_true[1]\n",
    "data_mixture = np.concatenate([draws_1, draws_2])\n",
    "plt.hist(data_mixture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, try using a two-component mixture distribution to calculate log-likelihood of data under parameters.\n",
    "\n",
    "The likelihood of the each data point is the sum of the likelihood of each data point under each of the components.\n",
    "\n",
    "The likelihood of a data point under a component $i$ is the likelihood of drawing that component * likelihood of observing that data point under that component's distribution. In Math:\n",
    "\n",
    "$$L_i = P(x|\\mu_i, w_i)P(w_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike_one_component(component_prob, component_mu, datum):\n",
    "    \"\"\"Log likelihood of datum under one component of the mixture.\"\"\"\n",
    "    return np.log(component_prob) + stats.norm.logpdf(datum, loc=component_mu, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we test-drive it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike_one_component(component_prob=0.25, component_mu=0., datum=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglike_across_components(component_probs, component_mus, datum):\n",
    "    \"\"\"Log likelihood of datum under all components of the mixture.\"\"\"\n",
    "    component_probs = component_probs / np.sum(component_probs, axis=-1)\n",
    "    return logsumexp(vmap(partial(loglike_one_component, datum=datum))(component_probs, component_mus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike_across_components(component_probs=np.array([10, 0.1]), component_mus=np.array([0., 3]), datum=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixture_loglike(component_probs, component_mus, data):\n",
    "    \"\"\"Log likelihood of data (not datum!) under all components of the mixture.\"\"\"\n",
    "    ll_per_data = vmap(partial(loglike_across_components, component_probs, component_mus))(data)\n",
    "    return np.sum(ll_per_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_loglike(component_probs=np.array([0.1, 0.1]), component_mus=np.array([0., 3]), data=np.array([0., 0., 0., 3., 3., 3.,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, data):\n",
    "    log_component_probs, component_mus = params\n",
    "    component_probs = np.exp(log_component_probs)\n",
    "    return -mixture_loglike(component_probs, component_mus, data)\n",
    "\n",
    "dloss = grad(loss)\n",
    "\n",
    "N_MIXTURE_COMPONENTS = 10\n",
    "\n",
    "log_component_probs_init = np.abs(random.normal(key, shape=(N_MIXTURE_COMPONENTS,)))\n",
    "component_mus_init = 10 * random.normal(key, shape=(N_MIXTURE_COMPONENTS,)) # np.array([0., 3., 5., 20.])\n",
    "observed_data = np.array([0., 0., 0., 3., 3., 3., 3., 3., 3., 3.,])\n",
    "\n",
    "params_init = log_component_probs_init, component_mus_init\n",
    "\n",
    "loss(params_init, observed_data), dloss(params_init, observed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try optimizing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit\n",
    "from jax.experimental.optimizers import adam\n",
    "\n",
    "def optimize_params(params, data, dloss, n_iter):\n",
    "    \"\"\"\n",
    "    Generic optimizer loop, using ADAM optimizer.\n",
    "    \n",
    "    Exists purely for convenience.\n",
    "    \n",
    "    :param params: The params to optimize.\n",
    "    :param data: The data, gets passed into the dloss function.\n",
    "    :param dloss: A function that returns a scalar loss to be minimized.\n",
    "        Accepts only `params` and `data`.\n",
    "    :param n_iter: Number of iterations to optimize for.\n",
    "    \"\"\"\n",
    "    init, update, get_params = adam(0.05)\n",
    "    get_params = jit(get_params)\n",
    "    \n",
    "    @jit\n",
    "    def step(i, state):\n",
    "        params = get_params(state)\n",
    "        g = dloss(params, data)\n",
    "        state = update(i, g, state)\n",
    "        return state\n",
    "\n",
    "    state = init(params)\n",
    "    for i in range(n_iter):\n",
    "        state = step(i, state)\n",
    "    return get_params(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opt = optimize_params(params_init, data_mixture, dloss, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(params_opt, data_mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_component_probs_opt = params_opt[0]\n",
    "component_probs_opt = np.exp(params_opt[0])\n",
    "component_probs_opt = component_probs_opt / np.sum(component_probs_opt)\n",
    "component_probs_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = params_opt[1]\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do the mixture PDFs look like here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.stats import norm\n",
    "\n",
    "def plot_component_norm_pdfs(component_probs, component_mus, xmin, xmax):\n",
    "    x = np.linspace(xmin, xmax, 1000).reshape(-1,1)\n",
    "    pdfs = component_probs * norm.pdf(x, loc=component_mus)\n",
    "    for component in range(pdfs.shape[1]):\n",
    "        plt.plot(x, pdfs[:, component])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_component_norm_pdfs(np.exp(log_component_probs_init), component_mus_init, -10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'd like to learn the concentration parameter for the component probs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import lax\n",
    "def beta_draw_from_weights(weights, tol=1e-8):\n",
    "    def beta_from_w(accounted_probability, weights_i):\n",
    "        \"\"\"\n",
    "        :param accounted_probability: The cumulative probability acounted for.\n",
    "        :param weights_i: Current value of weights to consider.\n",
    "        \"\"\"\n",
    "        denominator = 1 - accounted_probability\n",
    "        log_denominator = np.log(denominator)\n",
    "        \n",
    "        log_beta_i = np.log(weights_i) - log_denominator\n",
    "\n",
    "        newly_accounted_probability = accounted_probability + weights_i\n",
    "        \n",
    "        return newly_accounted_probability, np.exp(log_beta_i)\n",
    "    final, betas = lax.scan(beta_from_w, np.array(0.), weights)\n",
    "    return final, betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def component_probs_logpdf(component_probs, log_concentration):\n",
    "    \"\"\"\n",
    "    :param log_concentration: Real-valued scalar.\n",
    "    \"\"\"\n",
    "    concentration = np.exp(log_concentration)\n",
    "    component_probs = component_probs / np.sum(component_probs)\n",
    "    _, beta_draws = beta_draw_from_weights(component_probs)\n",
    "    return np.sum(stats.beta.logpdf(x=component_probs, a=1, b=concentration))\n",
    "_, beta_draws = beta_draw_from_weights(component_probs_opt)\n",
    "beta_draws\n",
    "\n",
    "component_probs_logpdf(component_probs_opt, log_concentration=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can calculate the component logpdfs, let's jointly look at them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_loss(params, data):\n",
    "    log_component_probs, log_concentration, component_mus = params\n",
    "    component_probs = np.exp(log_component_probs)\n",
    "    \n",
    "    # component probability distribution logpdf against beta distribution\n",
    "    comp_probs_logp = component_probs_logpdf(component_probs, log_concentration)\n",
    "    \n",
    "    # mixture distribution logpdf\n",
    "    mixture_logp = mixture_loglike(component_probs, component_mus, data)\n",
    "    \n",
    "    total_logp = comp_probs_logp + mixture_logp\n",
    "    regularization = np.power(log_concentration, 4)\n",
    "    return -total_logp + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "djoint_loss = grad(joint_loss)\n",
    "\n",
    "concentration_init = 3.\n",
    "\n",
    "params_init = log_component_probs_init, np.log(concentration_init), component_mus_init\n",
    "joint_loss(params_init, observed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opt = optimize_params(params_init, data_mixture, djoint_loss, n_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_component_probs_opt, log_concentration_opt, component_mus_opt = params_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_probs_opt = np.exp(log_component_probs_opt)\n",
    "component_probs_opt = component_probs_opt / component_probs_opt.sum()\n",
    "component_probs_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_mus_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentration_opt = np.exp(log_concentration_opt)\n",
    "concentration_opt, concentration_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_component_norm_pdfs(component_probs_opt, component_mus_opt, -10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_component_norm_pdfs(np.exp(log_component_probs_init), component_mus_init, -10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian",
   "language": "python",
   "name": "bayesian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

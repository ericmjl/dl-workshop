{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "subject-university",
   "metadata": {},
   "source": [
    "# Optimized Learning\n",
    "\n",
    "In this notebook, we are going to look at another one of JAX's functional transforms: the `grad` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-capital",
   "metadata": {},
   "source": [
    "## Autograd to JAX\n",
    "\n",
    "Before they worked on JAX, the JAX core team worked on another Python package called autograd.\n",
    "That was where the original idea of building an automatic differentiation system on top of NumPy started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-basement",
   "metadata": {},
   "source": [
    "## Example: Transforming a function into its derivative\n",
    "\n",
    "Just like `vmap`, `grad` takes in a function and transforms it into another function.\n",
    "By default, the returned function from `grad`\n",
    "is the derivative of the function with respect to the first argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-suicide",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example 1:\n",
    "from jax import grad\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return 3 * x + 1\n",
    "\n",
    "\n",
    "df = grad(func)\n",
    "\n",
    "\n",
    "# Pass in any float value of x, you should get back 3.0 as the _gradient_.\n",
    "df(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-moses",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example 2:\n",
    "\n",
    "\n",
    "def polynomial(x):\n",
    "    return 3 * x ** 2 + 4 * x - 3\n",
    "\n",
    "\n",
    "dpolynomial = grad(polynomial)\n",
    "\n",
    "# pass in any float value of x\n",
    "# the result will be evaluated at 6x + 4,\n",
    "# which is the gradient of the polynomial function.\n",
    "dpolynomial(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-strengthening",
   "metadata": {},
   "source": [
    "Using grad to solve minimization problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-breakdown",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: find the minima of the polynomial function.\n",
    "\n",
    "start = 3.0\n",
    "for i in range(200):\n",
    "    start -= dpolynomial(start) * 0.01\n",
    "start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-smart",
   "metadata": {},
   "source": [
    "How close is this to the true analytical value?\n",
    "\n",
    "$$f(x) = 3x^{2} + 4x -3$$\n",
    "$$\\frac{df}{dx} = 6x + 4$$\n",
    "\n",
    "At the minima, $\\frac{df}{dx}$ is zero. Therefore, $x = -\\frac{2}{3}$.\n",
    "\n",
    "We're pretty darn close.\n",
    "\n",
    "And that, my friends, is gradient descent!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-broadway",
   "metadata": {},
   "source": [
    "## maximum likelihood of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-laundry",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jax import random\n",
    "\n",
    "key = random.PRNGKey(44)\n",
    "real_mu = -3.0\n",
    "real_log_sigma = np.log(2.0)  # the real sigma is 2.0\n",
    "\n",
    "\n",
    "data = random.normal(key, shape=(1000,)) * np.exp(real_log_sigma) + real_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-shoulder",
   "metadata": {},
   "source": [
    "## what is the maximum likelihood value of mu and sigma given the data?\n",
    "\n",
    "equivalent to minimizing negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-terry",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jax.scipy.stats import norm\n",
    "import jax.numpy as np\n",
    "\n",
    "def neglogp(mu, log_sigma, data):\n",
    "    return -np.sum(norm.logpdf(data, loc=mu, scale=np.exp(log_sigma)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-highland",
   "metadata": {},
   "source": [
    "Check that calculation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-nursing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu = -6.0\n",
    "log_sigma = np.log(2.0)\n",
    "neglogp(mu, log_sigma, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-contract",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dneglogp = grad(neglogp, argnums=(0, 1))\n",
    "\n",
    "# condition on data\n",
    "dneglogp = partial(dneglogp, data=data)\n",
    "dneglogp(mu, log_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-detector",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# gradient descent\n",
    "for i in range(300):\n",
    "    dmu, dlog_sigma = dneglogp(mu, log_sigma)\n",
    "    mu -= dmu * 0.0001\n",
    "    log_sigma -= dlog_sigma * 0.0001\n",
    "mu, np.exp(log_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-grocery",
   "metadata": {},
   "source": [
    "## grad with multiple arguments\n",
    "\n",
    "Where is the gold? It's at the minima!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-precipitation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func(x, y):\n",
    "    \"\"\"All credit to https://www.analyzemath.com/calculus/multivariable/maxima_minima.html for this function.\"\"\"\n",
    "    return (2 * x ** 2) - (4 * x * y) + (y ** 4 + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-windows",
   "metadata": {},
   "source": [
    "It should be evident from here that there are two minima in the function.\n",
    "Let's find out where they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-initial",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = grad(func, argnums=[0, 1])\n",
    "df(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-privacy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start somewhere\n",
    "x, y = 0.1, -0.1\n",
    "for i in range(300):\n",
    "    dx, dy = df(x, y)\n",
    "    x -= dx * 0.01\n",
    "    y -= dy * 0.01\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-smart",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(-1.5, 1.5, 0.01)\n",
    "Y = np.arange(-1.5, 1.5, 0.01)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = func(X, Y)\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(\n",
    "    X, Y, Z, cmap=cm.coolwarm, linewidth=0, antialiased=False,\n",
    ")\n",
    "ax.view_init(elev=20., azim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-giant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-workshop",
   "language": "python",
   "name": "dl-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
